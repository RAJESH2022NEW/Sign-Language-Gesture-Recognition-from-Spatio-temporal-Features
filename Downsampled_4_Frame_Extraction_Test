# -*- coding: utf-8 -*-
"""Downsampled_4_Frame_Extraction_Test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UuKLoKuZYzxU2ZL98CKZ2xP77sXSUD9K
"""

from google.colab import drive
drive.mount('/content/drive')

import cv2
import os
import pickle
import numpy as np
from os.path import join, exists
from tqdm import tqdm

"""-- Confirm source and target folder for training or testing

-- Test
"""

Source_folder="/content/drive/MyDrive/Colab Notebooks/SLGR/Dataset/LSA_64/Test_set_videos"
Target_folder="/content/drive/MyDrive/Colab Notebooks/SLGR/Dataset/LSA_64/Test_Frames_Downsampled_4"

"""-- Remove handesegment (if using another dataset)"""

def handsegment(frame):
    boundaries = [
    ([0, 120, 0], [140, 255, 100]),
    ([25, 0, 75], [180, 38, 255])]

    lower, upper = boundaries[0]
    lower = np.array(lower, dtype="uint8")
    upper = np.array(upper, dtype="uint8")
    mask1 = cv2.inRange(frame, lower, upper)
    lower, upper = boundaries[1]
    lower = np.array(lower, dtype="uint8")
    upper = np.array(upper, dtype="uint8")
    mask2 = cv2.inRange(frame, lower, upper)
    mask = cv2.bitwise_or(mask1, mask2)
    output = cv2.bitwise_and(frame, frame, mask=mask)
    return output

hc = []
rootPath = os.getcwd()
if not exists(Target_folder):
    os.makedirs(Target_folder)

os.chdir(Source_folder)
gestures = os.listdir(os.getcwd())

print("Source Directory containing gestures: %s" % (Source_folder))
print("Destination Directory containing frames: %s\n" % (Target_folder))

for gesture in tqdm(gestures, unit='actions', ascii=True):
    gesture_path = os.path.join(Source_folder, gesture)
    os.chdir(gesture_path)
    gesture_frames_path = os.path.join(Target_folder, gesture)
    if not os.path.exists(gesture_frames_path):
        os.makedirs(gesture_frames_path)
    videos = os.listdir(os.getcwd())
    videos = [video for video in videos if(os.path.isfile(video))]
    for video in tqdm(videos, unit='videos', ascii=True):
        name = os.path.abspath(video)
        cap = cv2.VideoCapture(name)  
        frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        lastFrame = None
        os.chdir(gesture_frames_path)
        count = 0
        while count < 242:
           ret, frame = cap.read()  
           if ret is False:
              break
           if count%4 == 0 :
              framename = os.path.splitext(video)[0]
              framename = framename + "_frame_" + str(int(count/4)) + ".jpeg"
              hc.append([join(gesture_frames_path, framename), gesture, frameCount])
              if not os.path.exists(framename):
                  frame = handsegment(frame)
                  frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                  scale_percent = 30 # percent of original size
                  width_frame = int(frame.shape[1] * scale_percent / 100)
                  height_frame = int(frame.shape[0] * scale_percent / 100)
                  dim_frame= (width_frame, height_frame)
                  frame = cv2.resize(frame, dim_frame, interpolation = cv2.INTER_LINEAR)
                  lastFrame = frame
                  cv2.imwrite(framename, frame)
           if cv2.waitKey(1) & 0xFF == ord('q'):
                    break
           count += 1
        while count < 242:
            if count%4==0 :
                framename = os.path.splitext(video)[0]
                framename = framename + "_frame_" + str(int(count/4)) + ".jpeg"
                hc.append([join(gesture_frames_path, framename), gesture, frameCount])
                if not os.path.exists(framename):
                    cv2.imwrite(framename, lastFrame)
            count += 1
        os.chdir(gesture_path)
        cap.release()
        cv2.destroyAllWindows()
os.chdir(rootPath)

drive.flush_and_unmount()
