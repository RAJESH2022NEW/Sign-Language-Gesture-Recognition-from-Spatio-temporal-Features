# -*- coding: utf-8 -*-
"""Test_CNN_Feature_Vectors.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VO7iBLxRkulthjh3d-RTBctvVUMr9IjE
"""

!nvidia-smi

from google.colab import drive
drive.mount('/content/drive')

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
import numpy as np
import os
import pickle
import sys
import tensorflow as tf
from tqdm import tqdm

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

"""-- Confirm model Loaction"""

intermediate_graph= tf.keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/SLGR_ISL_Emergency_Signs/CNN/Inception_V3/Output/Saved_model')
intermediate_graph.trainable=False
layer_name="Feature_Layer"
layer_output=intermediate_graph.get_layer(layer_name).output
Feature_model=tf.keras.models.Model(inputs=intermediate_graph.input,outputs=layer_output)
Feature_model.summary()

def tensor_predict(model, image_tensor):
    results = model.predict(image_tensor)
    results = np.squeeze(results)
    return results

def read_tensor_from_image_file(frames, input_height=299, input_width=299, input_mean=0, input_std=255):
    input_name = "file_reader"
    frames = [(tf.compat.v1.read_file(frame, input_name), frame) for frame in frames]
    decoded_frames = []
    for frame in frames:
        file_name = frame[1]
        file_reader = frame[0]
        if file_name.endswith(".png"):
            image_reader = tf.image.decode_png(file_reader, channels=3, name="png_reader")
        elif file_name.endswith(".gif"):
            image_reader = tf.squeeze(tf.image.decode_gif(file_reader, name="gif_reader"))
        elif file_name.endswith(".bmp"):
            image_reader = tf.image.decode_bmp(file_reader, name="bmp_reader")
        else:
            image_reader = tf.image.decode_jpeg(file_reader, channels=3, name="jpeg_reader")
        decoded_frames.append(image_reader)
    float_caster = [tf.cast(image_reader, tf.float32) for image_reader in decoded_frames]
    float_caster = tf.stack(float_caster)
    resized = tf.compat.v1.image.resize_bilinear(float_caster, [input_height, input_width])
    normalized = tf.divide(tf.subtract(resized, [input_mean]), [input_std])
    sess = tf.compat.v1.Session()
    tf.compat.v1.disable_eager_execution()
    result = sess.run(normalized)
    return result

def load_labels(label_file):
    label = []
    proto_as_ascii_lines = tf.gfile.GFile(label_file).readlines()
    for l in proto_as_ascii_lines:
        label.append(l.rstrip())
    return label

input_height = 299
input_width = 299
input_mean = 0
input_std = 255
batch_size = 100
output_layer="Feature_layer"

"""**-- Feature Vector Extraction : Test dataset**

1. Test Dataset
"""

frames_folder="/content/drive/MyDrive/Colab Notebooks/SLGR_ISL_Emergency_Signs/Dataset/ISL_Emergency_Signs/Test_Frames"
train_or_test = "test"

labels_in_dir = os.listdir(frames_folder)
frames = [each for each in os.walk(frames_folder) if os.path.basename(each[0]) in labels_in_dir]
predictions = []
for each in frames:
        label = each[0]
        print("Predicting on frame of %s\n" % (label))
        for i in tqdm(range(0, len(each[2]), batch_size), ascii=True):
            batch = each[2][i:i + batch_size]
            try:
                batch = [os.path.join(label, frame) for frame in batch]
                frames_tensors = read_tensor_from_image_file(batch, input_height=input_height, input_width=input_width, input_mean=input_mean, input_std=input_std)
                pred= tensor_predict(Feature_model,frames_tensors)
                pred = [[each.tolist(), os.path.basename(label)] for each in pred]
                predictions.extend(pred)

            except KeyboardInterrupt:
                print("You quit with ctrl+c")
                sys.exit()

            except Exception as e:
                print("Error making prediction: %s" % (e))
                x = input("\nDo You Want to continue on other samples: y/n")
                if x.lower() == 'y':
                    continue
                else:
                    sys.exit()

out_file = "/content/drive/MyDrive/Colab Notebooks/SLGR_ISL_Emergency_Signs/CNN/Inception_V3/Output/Inception_V3_Feature_Vectors_frames_%s_%s.pkl" % (output_layer.split("/")[-1], train_or_test)
print("Dumping predictions to: %s" % (out_file))
with open(out_file, 'wb') as fout:
        pickle.dump(predictions, fout)

print("Done.")
